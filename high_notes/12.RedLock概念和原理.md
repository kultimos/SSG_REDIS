# RedLock引入的原因
  RedLock实现了我们认为比普通单实例方法更安全的DLM;
  说个场景:
  - 当前客户端A通过redis命令建立分布式锁并持有该锁,那么在集群部署下,正常情况主从机都有这分布式锁
  - 但是在故障情况下,可能出现,master还未将分布式锁同步给slave,就宕机了,那么此时slave如果上位成为新的master,就丢失了分布式锁的记录
  - 如果此时客户端B来获取锁,照样可以持有分布式锁,这就出现了一锁被多键多用的情况
  Redis提供了RedLock算法,用来实现基于多个实例的分布式锁;锁变量由多个实例维护,即使有实例发生了故障,锁变量仍然是存在的,客户端还是可以完成锁操作;

# RedLock的分布式锁方案
  该方案也是基于set加锁、lua脚本解锁进行改良的,但下面的描述中我们只描述差异之处,大致如下
  假设我们由N个redis节点,例如N=5,这些节点是完全独立的,我们不使用复制或任何其他隐式协调系统
  为了取得锁客户端执行以下操作:
  - 获取当前时间,以毫秒为单位
  - 依次尝试从5个实例,以相同的key和随机值获取锁,当向redis请求获取锁时,客户端应设置一个超时时间,这个超时时间应该小于锁的失效时间;例如你的锁自动失效时间是10秒,
  则超时时间应该在5-50毫秒之间,这样可以防止客户端在试图与一个宕机的Redis节点对话时,长时间处于阻塞状态;如果一个实例不可用,客户端应该尽快尝试去另外一个redis实例
  请求获取锁;
  - 客户端通过当前时间减去第一步获取的时间来计算获取锁使用的时间,当且仅当从大多数(N/2+1.这里N=5，所以结果是3个节点)的redis节点都获取锁,并且获取锁使用的时间小于
  锁失效的时间时,锁才算获取成功
  - 如果取得了锁,其真正有效时间等于初始有效时间减去获取锁所使用的时间,锁所使用的时间即为(第三步的结果)
  - 如果由于某些原因未能获取锁(无法在至少N/2 + 1个redis实例获取锁、或获取锁的时间超过了有效时间),客户端应该在所有的redis实例上进行解锁(即便某些redis实例根本就没有加锁成功,
  这是为了防止某些节点获取到锁,但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁)
  该方案为了解决数据因主节点宕机可能导致的锁被多客户端获取的问题,直接舍弃了异步复制,只使用master节点,同时由于舍弃了slave,为了保证可用性,引入了N个节点,官方建议是5;