# BigKey相关面试题整理
  - 海量数据里查询某一固定前缀的key
  - 如何在生产上限制keys */flushdb/flushall等危险命令以防误删误用
  - MEMORY USAGE命令是否使用过
  - BigKey问题,多大算big？如何发现？如何删除？
  - 生成上redis有1000w条记录,如何遍历？keys *可行吗

# MoreKey案例
  - 大批量往redis里面插入2000W测试数据key
    执行命令: for((i=1;i<=100*10000;i++)); do echo "set k$i v$i" >> /tmp/redisText.txt; done;
    可生成1000000条记录存放在redisText中,再通过管道--pipe命令将数据存入redis中
    执行命令: cat /tmp/redisText.txt | redis-cli -a 1234567a --pipe

  - 生产上如何限制 keys * / flushdb / flushall等危险命令,以防止误删误用问题？
    通过配置设置禁用这些命令,redis.conf中配置需要禁用的命令,重启后这些命令就不再允许被使用;
    rename-command keys ""
    rename-command flushdb ""
    rename-command flushall ""

  - keys * 命令因为其可能造成的后果而被我们禁用,但是面对数据时我们总是需要获悉我们都有哪些key,那在keys *被禁用之后,有没有类似的功能呢
    或者说我现在在redis中希望获取10条键为key开头的数据,有没有可以实现的方案呢?
    scan,scan命令可以完成上述的两种场景!
    命令: scan cursor [Match pattern] [Count count],cursor表示游标,Match和Count是两个关键字,pattern和count可以根据我们的需求自行设置;
    scan是基于游标的迭代器,需要基于上一次的游标延续之前的迭代过程,以0作为游标开始一次新的迭代,直到命令返回游标0完成一次遍历;不保证每次执行都返回某个给定数量的元素,支持模糊查询,
  一次返回的数量不可控,只能是大概率符合count参数;
    scan命令使用演示:
    127.0.0.1:6379> scan 0   , Match和Count都可以省略,不过未指定count,默认是10,并且未指定Match相当于select *,
    1) "327680"              ,返回结果由两部分组成,分别是下一次跌打的游标点位327680和这次迭代出的数据
    2) 1) "k753698"
       2) "k99759"
       3) "k735001"
       4) "k40341"
       5) "k730314"
       6) "k40341"
       7) "k70888"
       8) "k40332"
       9) "k844453"
       10) "k391975"
    因为返回的游标点位不是0,说明我们没有把所有key都迭代过,如果希望继续跌打可以这样:
    127.0.0.1:6379> scan 327680, 延用上一次迭代返回的游标继续迭代;当然我们可以随便指定游标,也可以迭代出内容,但这样我们就无法确定我们在哪一次迭代时把所有数据都查询过了;
    1) "884736"                  若希望保证迭代数据的准确性,就需要按照使用规范,scan 0开始迭代,直到某一次跌倒返回的游标是0,代表所有key的迭代均完成;
    2) 1) "k89592"
       2) "k950854"
       3) "k16845"
       4) "k797182"
       5) "k605394"
       6) "k270674"
       7) "k172091"
       8) "k602309"
       9) "k525459"
       10) "k665329"
    可以看到这次迭代仍没有结束,只有当返回的游标是0时,才表示迭代的结束,至于Match只是对key进行模糊匹配,所以不放具体案例了,只放一条命令即可;
    scan 0 match k*1* count 10,返回的内容大概是: k735001"、"k154621"、"k40341"、"k391975"、"k730314"

# BigKey案例
  - 多大算BigKey？
    首先需要清楚,大多数情况下,大的不是key本身,而是它对应的value
    根据《阿里云Redis开发规范》,强制要求拒绝BigKey(防止网卡流量、慢查询),string类型控制在10kb以内,hash、list、set、zset元素个数不要超过5000;并且非字符串的bigkey,不要使用
  del进行删除,要使用hscan、sscan、zscan查找后,再部分del的方式渐进式删除,同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置一小时过期,则会触发del操作,造成阻塞,
  而且该操作不会出现在慢查询中(latency可查));
    string是value,最大512MB,但是超过10KB就是bigkey;list、hash、set和zset,个数超过5000就是bigkey,但是这些集合理论上支持的元素最多是2^32-1个,约42亿;
  - BigKey的危害: 内存不均、集群迁移困难;超时删除,大key删除作梗;网络流量阻塞
  - BigKey如何产生: 首先明确,BigKey问题很难避免,无论是短时间内的数据暴涨,还是经年累月的数据堆积都会产生BigKey的问题;
  - 如何发现当前服务中的BigKey
    - redis-cli --bigkeys ,该命令会扫描所有键,并返回占用内存最多的键及其对应的内存使用量
    - MEMORY USAGE kName, kName表示键名,该命令可以获取指定键的内存使用量
  - 如何进行BigKey的删除
    - 参考《阿里云Redis开发规范》: 非字符串的BigKey不要使用del进行删除,而要先通过scan扫描,再针对集合中的每个元素使用del进行删除,这就是所谓渐进式删除;